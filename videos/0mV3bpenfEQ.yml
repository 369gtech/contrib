# Editing guidelines: https://github.com/watch-devtube/contrib/#how-to-edit-video-metadata

category: conference
tags:
    - storage
    - bigdata
    - ml
    - architecture
title: 'YOW! Data 2018 - Dean Wampler - Stream All the Things!!'
language: English
recordingDate: 1530576001
description: "Streaming data architectures aren't just \"faster\" Big Data architectures. They must be reliable and scalable as never before, more like microservice architectures.\n\nThis talk has three goals:\n\n   1. Justify the transition from batch-oriented big data to stream-oriented fast data.\n  2.  Explain the requirements that streaming architectures must meet and the tools and techniques used to meet them.\n   3. Discuss the ways that fast data and microservice architectures are converging.\n\nBig data started with an emphasis on batch-oriented architectures, where data is captured in large, scalable stores, then processed using batch jobs. To reduce the gap between data arrival and information extraction, these architectures are now evolving to be stream oriented, where data is processed as it arrives. Fast data is the new buzz word.\n\nThese architectures introduce new challenges for developers. Whereas a batch job might run for hours, a stream processing system typically runs for weeks or months, which raises the bar for making these systems reliable and scalable to handle any contingency.\n\nThe microservice world has faced this challenge for a while. Microservices are inherently message driven, responding to requests for service and sending messages to other microservices, in turn. Hence, they are also stream oriented, in the sense that they must respond reliably to never-ending input. So, they offer guidance for how to build reliable streaming data systems. I'll discuss how these architectures are merging in other ways, too.\n\nWe'll also discuss how to pick streaming technologies based on four axes of concern:\n\n   1. Low latency: What's my time budget for handling this data?\n   2. High volume: How much data per unit time must I handle?\n   3. Data processing: Do I need machine learning, SQL queries, conventional ETL processing, etc.?\n   4. Integration with other tools: Which ones and how is data exchanged between them?\n\nWe'll consider specific examples of streaming tools and how they fit on these axes, including Spark, Flink, Akka Streams, and Kafka."
