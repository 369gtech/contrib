# Contribution guide: https://github.com/watch-devtube/contrib

# speaker:
#   name: _____
#   twitter: _____ # mandatory twitter handle; must not include @

# tags: [____, _____, _____]

title: 'Stand up for ethical AI! How to detect and mitigate AI bias using K... Andrew Butler & Animesh Singh'
language: English
recordingDate: 1621018757
description: "Don’t miss out! Join us at our upcoming event: KubeCon + CloudNativeCon North America 2021 in Los Angeles, CA from October 12-15. Learn more at https://kubecon.io The conference features presentations from developers and end users of Kubernetes, Prometheus, Envoy, and all of the other CNCF-hosted projects.\n\nStand up for ethical AI! How to detect and mitigate AI bias using Kubeflow - Andrew Butler & Animesh Singh, IBM\n\nThe application of AI algorithms in domains such as criminal justice, credit scoring, and hiring holds great promise. At the same time, it raises legitimate concerns about algorithmic fairness. There’s a growing demand for fairness, accountability, and transparency in ML systems. It is important to note that training data isn’t the only source of possible bias and adversarial contamination. It can also be introduced through inappropriate data handling or model selection, or even incorrect algorithm design. To address this, this talk will examine how to build a pipeline that’s open, transparent, secure, fair, and that fully integrates into the AI lifecycle by leveraging Kubeflow Pipelines. Then the correct method to deploy machine learning models in production and collect payloads to enable inbuilt bias checkers using KFServing will be detailed."
