# Editing guidelines: https://github.com/watch-devtube/contrib/#how-to-edit-video-metadata

tags:
    - ml
    - mobile
title: 'Irina Vidal MigallÃ³n: Using adversarial samples to robustify your Neural Network Models at Crunch'
recordingDate: 1572508107
description: "ðŸ‘‰ Learn more about the talk and download the slides at https://crunchconf.com/speaker/irinavidalmigallon#talks\nðŸ“¬ Sign up to our newsletter so you won't miss the updates about the next Crunch Data Conference: http://eepurl.com/dGwi1f\n\nIndustrial Computer Vision systems rely on Deep Neural Networks â€” also in production. If we should poke our code until it breaks, why would deep learning models get a free pass? We'll see different ways in which to poke our models and improve them, from the practitioner's point of view, who has access to the model. \n\nAttacks keep improving and getting more sophisticated, but that doesn't mean that practitioners cannot aim at improving models with the resources they have: from very basic techniques applicable from day 1 to sophisticated adversarial training. There is much that can be done to poke holes, expose biases and weaknesses, understand them and with all this improve your models before letting them loose. - Captured Live on Ustream at https://www.ustream.tv/crunch with the Ustream Mobile App"
