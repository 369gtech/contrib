# Contribution guide: https://github.com/watch-devtube/contrib

# speaker:
#   name: _____
#   twitter: _____ # mandatory twitter handle; must not include @

# tags: [____, _____, _____]

tags:
    - ml
    - containers
    - docker
    - testing
    - python
title: 'Shreya Khurana - Train. Serve. Deploy! Story of a NLP Model ft. PyTorch, Docker, Uwsgi and Nginx'
language: English
recordingDate: 1600696206
description: "\"Train. Serve. Deploy! Story of a NLP Model ft. PyTorch, Docker, Uwsgi and Nginx\nEuroPython 2020 - Talk - 2020-07-23 - Parrot Data Science\nOnline\n\nBy Shreya Khurana\n\nNatural language processing has seen leaps of technology progress with Machine Learning becoming the norm of solving the major problems in this area, with Machine translation being one of the major problems in this area. Neural machine translation systems are now used to convert sentences or phrases from one language to another, or in general, for sequence to sequence modeling. In this talk, we’ll be covering the steps from scratch to preprocess, train and serve a NMT model using PyTorch. While building a highly accurate model is a prerequisite to getting good quality translations, often in industry, we also need to make sure we can serve the model to customers without getting timeouts or delays. The practice of serving models requires creating a web app to get client requests and process them in a way the model would understand. For this, we’ll use  the various components of the application server environment - Flask, Docker, uwsgi and nginx. This talk is suitable for audience who is working in general with ML models and want to learn how to serve them or working specifically with NMT and want to learn about some quick prototyping tips. \n\nPrerequisites: Audience should be comfortable with the basic ML terminology and procedure of training models. NLP knowledge will be good, but is not a necessity as the focus will be on quick prototyping in production.\n\nBy the end of the talk, the audience will have:\n- Learnt how to preprocess data for NLP systems\n- Learnt how to quickly prototype and train a translation model\n- Learnt how to create a web app for the NLP model using Flask\n- Learnt how to containerize a pytorch model using Docker\n- Learnt how to serve the model as an app using uwsgi, nginx and \n\nOutline:\n\n\nIntroduction to translation systems, machine translation framework\n\n\nML Modelling \n- Preprocessing data\n- Training \n- Generating new translations \n\nServing and prototyping \n- Flask app \n- Docker container br /\n- Nginx + uwsgi + supervisord configurations \n- Putting it all together \n\nGood practices \nQ/A (optional?)\n\n\n\nLicense: This video is licensed under the CC BY-NC-SA 3.0 license: https://creativecommons.org/licenses/by-nc-sa/3.0/\nPlease see our speaker release agreement for details: https://ep2020.europython.eu/events/speaker-release-agreement/\n\n    \""
