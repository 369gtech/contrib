# Editing guidelines: https://github.com/watch-devtube/contrib/#how-to-edit-video-metadata

title: 'Sparse codes for natural sounds'
recordingDate: 1212144803
description: "Google Tech Talks\nMay, 20 2008\n\nABSTRACT\n\nThe auditory neural code must serve a wide range of tasks that\nrequire great sensitivity in time and frequency and be effective over the\ndiverse array of sounds present in natural acoustic environments. It has\nbeen suggested (Barlow, 1961; Atick, 1992; Simoncelli & Olshausen, 2001;\nLaughlin & Sejnowski, 2003) that sensory systems might have evolved highly\nefficient coding strategies to maximize the information conveyed to the\nbrain while minimizing the required energy and neural resources. In this\ntalk, I will show that, for natural sounds, the complete acoustic waveform\ncan be represented efficiently with a nonlinear model based on a population\nspike code. In this model, idealized spikes encode the precise temporal\npositions and magnitudes of underlying acoustic features. We find that when\nthe features are optimized for coding either natural sounds or speech, they\nshow striking similarities to time-domain cochlear filter estimates, have a\nfrequency-bandwidth dependence similar to that of auditory nerve fibers, and\nyield significantly greater coding efficiency than conventional signal\nrepresentations. These results indicate that the auditory code might\napproach an information theoretic optimum and that the acoustic structure of\nspeech might be adapted to the coding capacity of the mammalian auditory\nsystem.\n\nSpeaker: Vivienne Ming\nVivienne Ming was born in 1971 in Pasadena, CA. She received\nher B.S. (2000) in Cognitive Neuroscience from UC San Diego, developing face\nand expression recognition systems in the Machine Perception Lab. She earned\nher M.A. (2003) and Ph.D. (2006) in Psychology from Carnegie Mellon\nUniversity along with a doctoral training degree in computational\nneuroscience from the Center for the Neural Basis of Cognition. Her\ndissertation, *Efficient auditory coding*, combined computational and\nbehavioral approaches to study the perception of natural sounds, including\nspeech. Since 2006, she has worked jointly as a junior fellow and\npost-doctoral researcher at the Redwood Center for Theoretical Neuroscience\nat UC Berkeley and MBC/Mind, Brain & Cognition at Stanford University."
