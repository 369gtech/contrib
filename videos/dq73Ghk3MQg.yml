# Editing guidelines: https://github.com/watch-devtube/contrib/#how-to-edit-video-metadata

tags:
    - storage
    - bigdata
    - ml
    - python
title: 'PySpark Dataframes Tutorial | Introduction to PySpark Dataframes API | PySpark Training | Edureka'
language: English
recordingDate: 1530252757
description: "** PySpark Certification Training: https://www.edureka.co/pyspark-certification-training **\nThis Edureka video will provide you with a comprehensive and detailed knowledge of Dataframes, and how to use Dataframes in PySpark. Below are the topics covered in the video:\n\n1. Need for Dataframes\n2. What are Dataframes\n3. Dataframes Features\n4. Sources of Dataframes\n5. Hands On - Pyspark Dataframes\n\nSubscribe to our channel to get video updates. Hit the subscribe button above.\n\nEdureka PySpark Playlist: https://goo.gl/pCym9F\n\n--------------------------------------------\n\nAbout the Course\n\nEdureka’s PySpark Certification Training is designed to provide you the knowledge and skills that are required to become a successful Spark Developer using Python and prepare you for the Cloudera Hadoop and Spark Developer Certification Exam (CCA175). Throughout the PySpark Training, you will get an in-depth knowledge of Apache Spark and the Spark Ecosystem, which includes Spark RDD, Spark SQL, Spark MLlib and Spark Streaming. You will also get comprehensive knowledge of Python Programming language, HDFS, Sqoop, Flume, Spark GraphX and Messaging System such as Kafka.\n\n----------------------------------------------\n\nSpark Certification Training is designed by industry experts to make you a Certified Spark Developer. The PySpark Course offers:\nOverview of Big Data & Hadoop including HDFS (Hadoop Distributed File System), YARN (Yet Another Resource Negotiator)\nComprehensive knowledge of various tools that fall in Spark Ecosystem like Spark SQL, Spark MlLib, Sqoop, Kafka, Flume and Spark Streaming\nThe capability to ingest data in HDFS using Sqoop & Flume, and analyze those large datasets stored in the HDFS\nThe power of handling real-time data feeds through a publish-subscribe messaging system like Kafka\nThe exposure to many real-life industry-based projects which will be executed using Edureka’s CloudLab\nProjects which are diverse in nature covering banking, telecommunication, social media, and government domains\nRigorous involvement of an SME throughout the Spark Training to learn industry standards and best practices\n---------------------------------------------------\n\nWho should go for this course?\n\nThe market for Big Data Analytics is growing tremendously across the world and such strong growth pattern followed by market demand is a great opportunity for all IT Professionals. Here are a few Professional IT groups, who are continuously enjoying the benefits and perks of moving into Big Data domain.\n\nDevelopers and Architects\nBI /ETL/DW Professionals\nSenior IT Professionals\nMainframe Professionals\nFreshers\nBig Data Architects, Engineers and Developers\nData Scientists and Analytics Professionals\n\n-------------------------------------------------------\n\nThere are no such prerequisites for Edureka’s PySpark Training Course. However, prior knowledge of Python Programming and SQL will be helpful but is not at all mandatory.\n\n--------------------------------------------------------\n\nFor more information, please write back to us at sales@edureka.co\nCall us at US: +18336900808 (Toll Free) or India: +918861301699\n\nFacebook: https://www.facebook.com/edurekaIN/\nTwitter: https://twitter.com/edurekain\nLinkedIn: https://www.linkedin.com/company/edureka"
