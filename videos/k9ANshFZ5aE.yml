# Contribution guide: https://github.com/watch-devtube/contrib

# speaker:
#   name: _____
#   twitter: _____ # mandatory twitter handle; must not include @

# tags: [____, _____, _____]

title: 'How Could the Mind be Storing Information?'
language: English
recordingDate: 1622791084
description: "A Google TechTalk, presented by Rina Panigrahy , 2021/05/26\nABSTRACT:  Let's say you just finished a meeting -- how would your mind remember and organize all the information related to the meeting? Who did you meet, what was spoken, what was in the presentations, roughly how many people were there, what were the details? Such information needs to be organized and indexed in a way so that it can be quickly accessed in future if say I met someone from the meeting later to chat about some related topic.We propose that information related to such events and inputs is stored as a sketch -- the sketching mechanism is based on random subspace embedding and is able to approximately reconstruct the original input and its basic statistics up to some level of accuracy. The sketching mechanism implicitly enables different high level object oriented abstractions such as classes, attributes, references, type-information, modules into a knowledge graph without explicitly incorporating such ideas into the mechanism operations. We will see how a simplified implementation of Neural Memory based on storing sketches using Locality Sensitive Hashing can be used to almost double the capacity of BERT with a small amount of Neural Memory while adding less than 1% FLOPS. (Based on https://arxiv.org/abs/1905.12730, http://proceedings.mlr.press/v130/panigrahy21a/panigrahy21a.pdf, https://arxiv.org/abs/1910.06718).\n\nAbout the Speaker: Rina Panigrahy, Research Scientist, Google"
