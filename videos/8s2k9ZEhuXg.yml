# Editing guidelines: https://github.com/watch-devtube/contrib/#how-to-edit-video-metadata


title: 'Bias in NLP | Navid Rekabsaz'
recordingDate: 1545384063
description: "Recent advances in Word Embedding models (representation of words in high-dimensional vectors) provide promising results in capturing semantics of language, becoming the essential building blocks of many Natural Language Processing (NLP) applications—from search engines and job recommendation platforms to automatic machine translators. Since these models are often trained on large amount of historical data, they automatically capture the inherent bias in data, which can potentially cause ethical bias in our decision making. In this talk, Navid first explains the fundamentals as well as interesting qualities of the word2vec algorithm, an effective and efficient neural network-based approach to word embedding. He then discusses a recent study to show how the definitions of several occupations, captured by word2vec from the English Wikipedia text, are biased towards either female or male.\n\nVisit the largest developer playground in Europe!\nhttps://www.wearedevelopers.com/\n\nFacebook: https://www.facebook.com/wearedevelopers\nTwitter: https://twitter.com/WeAreDevs\nInstagram: https://www.instagram.com/_wearedevelopers/\n\n#WeAreDevs"
