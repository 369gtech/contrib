# Contribution guide: https://github.com/watch-devtube/contrib

# speaker:
#   name: _____
#   twitter: _____ # mandatory twitter handle; must not include @

# tags: [____, _____, _____]

title: 'Boosted and Differentially Private Ensembles of Decision Trees'
language: English
recordingDate: 1622842526
description: "A Google TechTalk, 2020/7/29, presented by Richard Nock, Data61 and The Australian National University\nABSTRACT: Ensembles of decision tree (DT) classifiers are hugely popular in\nboth the private and non-private settings, and display a very singular\npicture: while boosting and offsprings top international competitions\nin the non-private setting, random forests reign supreme\nwhen differential privacy (DP) is at stake. There is no middle ground\nthat would combine the rates of boosting with the randomness that DP\ncommands. In this talk, we summarise (i) the existence of a privacy vs boosting dilemma for top-down induction of DTs in the context of statistical decision theory, (ii) an algorithm to navigate this dilemma with the introduction of a new specifically designed proper loss and a way to tune it at training time to make the most of boosting under DP constraints, (iii) formal boosting convergence results under DP constraints and (iv) experiments comparing our approach to differentially private random forests."
