# Editing guidelines: https://github.com/watch-devtube/contrib/#how-to-edit-video-metadata


tags:
    - testing
title: 'Interpretability Beyond Feature Attribution'
recordingDate: 1542599008
description: "Quantitative Testing with Concept Activation Vectors (TCAV)\nBeen Kim, Senior Research Scientist, Google Brain\nPresented at MLconf 2018\nAbstract: I will share some of the recent results for improving interpretability when you already have a model (post-training interpretability) and our work on ways to test interpretability methods. Among them, I will take a deeper dive in one of my recent work – testing with concept activation vectors (TCAV) – a post-training interpretability method for complex models, such as neural network. This method provides an interpretation of a neural net’s internal state in terms of human-friendly, high-level concepts instead of low-level input features. The key idea is to view the high-dimensional internal state of a neural net as an aid, not an obstacle. We show how to use concept activation vectors (CAVs) as part of a technique, Testing with CAVs (TCAV), that uses directional derivatives to quantify the degree to which a user-defined concept is important to a classification result–for example, how sensitive a prediction of “zebra” is to the presence of stripes. Using the domain of image classification as a testing ground, we describe how CAVs may be used to explore hypotheses and generate insights for a standard image classification network as well as a medical application.\n\nSee Been's presentation slides on our slideshare page here: https://www.slideshare.net/SessionsEvents/interpretability-beyond-feature-attribution-quantitative-testing-with-concept-activation-vectors-tcav-123005780?qid=8d8e6060-a2e6-4194-baf0-93a7f8d1bff5&v=&b=&from_search=14"
