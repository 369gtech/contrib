# Editing guidelines: https://github.com/watch-devtube/contrib/#how-to-edit-video-metadata

tags:
    - bigdata
    - python
    - java
    - functional
title: 'Irina Truong - Adapting from Spark to Dask: what to expect - PyCon 2018'
recordingDate: 1526153894
description: "Speaker: Irina Truong\n\nUntil very recently, Apache Spark has been a de facto standard choice of a framework for batch data processing. For Python developers, diving into Spark is challenging, because it requires learning the Java infrastructure, memory management, configuration management. The multiple layers of indirection also make it harder to debug things, especially when throwing the Pyspark wrapper into the equation.\n\nWith Dask emerging as a pure Python framework for parallel computing, Python developers might be looking at it with new hope, wondering if it might work for them in place of Spark. In this talk, Iâ€™m using a data aggregation example to highlight the important differences between the two frameworks, and make it clear how involved the switch may be.\n\nNote: Just in case it's unclear, there's no Java of any kind in this talk. All the code / examples use Python (PySpark).\n\n\nSlides can be found at: https://speakerdeck.com/pycon2018 and https://github.com/PyCon/2018-slides"
