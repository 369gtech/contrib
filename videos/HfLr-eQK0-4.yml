# Contribution guide: https://github.com/watch-devtube/contrib

# speaker:
#   name: _____
#   twitter: _____ # mandatory twitter handle; must not include @

# tags: [____, _____, _____]

title: 'Meetup #AperiTech Online Edition 10/02/2021 - Deep Learning Italia - Online Conference'
language: English
recordingDate: 1613132723
description: "Deep Learning Italia” Online Conference.\n\nSi affrontano temi legati esclusivamente alla progettazione e implementazione di Reti Neurali e il Deep Learning nell'Intelligenza Artificiale di oggi.\nIl Meetup di DLI nasce dall'esigenza di sopperire alla carenza di meetup tecnici sul Deep Learning in Italia mentre ormai se ne contano molteplici in altre città del mondo come Londra, Amsterdam e San Francisco. Il Meetup è orientato sia alla ricerca accademica e che al mondo delle startup.\n\nSpeaker: Patrick von Platen at Research Engineer at Hugging Face\n\nBio:\nPatrick von Platen is a research engineer at Hugging Face and one of the core maintainers of Transformers. He specializes in encoder-decoder models and long-range sequence modeling. Before joining Hugging Face, Patrick conducted research in speech recognition at Uber AI, Cambridge University, and RWTH Aachen University.\n\nTitle of Talk:\nTransformer Sequence-to-Sequence Models - Concepts, Trends & Limitations\n\nAbstract:\nRNNs were the first end-to-end neural networks to effectively solve sequence-to-sequence (seq2seq) tasks.\nSince 2017, Transformer-based models have largely replaced RNNs and now have now become the de-facto standard architecture for seq2seq tasks in NLP. In this talk, we will outline the advantages Transformer-based models have over RNNs, present current research trends, and explain their limitations. Current research trends of transformer-based seq2seq models, we cover include pretraining (e.g. T5, Bart), long-range sequence modeling (e.g. BigBird, Longformer), and warm-starting.\n\n\nPer restare aggiornato su tutti gli #AperiTech:\nTelegram #AperiTech https://t.me/aperitech\nCalendario del Developer https://bit.ly/devcalendar\nCodemotion Tech Community https://bit.ly/CodemotionTC"
