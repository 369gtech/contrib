# Editing guidelines: https://github.com/watch-devtube/contrib/#how-to-edit-video-metadata

tags:
    - testing
title: 'Latency and Cost Tradeoffs for Efficient Peer-to-Peer Assisted Content Distribution'
recordingDate: 1258999588
description: "Google Tech Talk\nNovember 19, 2009\n\nABSTRACT\n\nPresented by Srinivas Shakkottai.\n\nThe Internet was conceived as a medium to efficiently enable point-to-point conversations.  However, the main source of Internet traffic today is easily duplicable and location-independent content. In this talk we will focus on three aspects of latency and costs for P2P-assisted content distribution using analytical models supported by real-world measurements.\n\nOur first focus in this talk is on utilizing awareness of demand for a piece of content in the interest of efficient resource usage.  Suppose that we can use a centralized server and/or a P2P network for content distribution.   What would the latency experienced by users look like?  We use the Bass model of demand evolution to compare a hybrid of peer-to-peer and a centralized client-server approach against each method acting alone.  Can we determine how to combine server and P2P methods so as to minimize the latency experienced by users while maintaining low server utilization?\n\nIn the second we focus on developing ISP-friendly P2P content distribution.  P2P content distribution often increases transit cost to Internet Service Providers (ISPs), as peers exchange large  amounts of trafﬁc across ISP boundaries. This ISP oblivious  behavior has resulted in misalignment of incentives between P2P networks—that seek to maximize user quality—and ISPs—that  would seek to minimize costs. Can we design a P2P overlay that  accounts for both ISP costs as well as quality of service, and attains a desired tradeoff between the two?\n\nIn the third we briefly consider the use of P2P networks for real-time streaming.  In such P2P streaming systems, each peer maintains a playout buffer of content chunks which it attempts to ﬁll by contacting other peers in the network. The objective is to ensure that the chunk to be played out is available with high probability while keeping the buffer size small.   Our question is: Can we determine a policy that minimizes the buffer size for a given  target probability of skip-free playout?\n\nSrinivas Shakkottai received the M.S. (2003) and PhD (2007) degrees, both in electrical engineering, from the University of Illinois at Urbana-Champaign.  He was a post-doctoral scholar at Stanford University in 2007, and is currently an assistant professor at the Dept. of ECE at Texas A&M University.\n\nHis research interests include content distribution systems, wireless ad-hoc networks, Internet economics and game theory, congestion control, and the measurement and analysis of Internet data.\n\nSrinivas is the recipient of the National Merit Scholarship, and the Young Scientist Fellowship, (Dept. of Science and Technology, Govt. of India), and the International Programs in Engineering Fellowship at the University of Illinois.  He also recently received the Defense Threat Reduction Agency (DTRA) Young Investigator Award."
