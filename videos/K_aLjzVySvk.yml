# Editing guidelines: https://github.com/watch-devtube/contrib/#how-to-edit-video-metadata


tags:
    - unix
    - storage
    - bigdata
    - ml
    - python
title: 'PySpark Installation | Configure Jupyter Notebook with PySpark | PySpark Tutorial | Edureka'
language: English
recordingDate: 1531805343
description: "** PySpark Certification Training: https://www.edureka.co/pyspark-certification-training **\nThis Edureka video on PySpark Installation will provide you with step by step installation of PySpark on a Linux Environment. This video is on CentOs but the steps are the same for Ubuntu as well. It will also provide you with the hardware as well as the software requirements for the installation. This video covers the following topics:\n\n1.Hardware Requirements\n2. Software Requirements\n3. Installation Process\n4. PySpark Demo\n\n-------------------------------------------\n\nAbout the Course\n\nEdureka’s PySpark Certification Training is designed to provide you with the knowledge and skills that are required to become a successful Spark Developer using Python and prepare you for the Cloudera Hadoop and Spark Developer Certification Exam (CCA175). Throughout the PySpark Training, you will get an in-depth knowledge of Apache Spark and the Spark Ecosystem, which includes Spark RDD, Spark SQL, Spark MLlib and Spark Streaming. You will also get comprehensive knowledge of Python Programming language, HDFS, Sqoop, Flume, Spark GraphX and Messaging System such as Kafka.\n\n----------------------------------------------\n\n    Spark Certification Training is designed by industry experts to make you a Certified Spark Developer. The PySpark Course offers:\n\n    Overview of Big Data & Hadoop including HDFS (Hadoop Distributed File System), YARN (Yet Another Resource Negotiator)\n    Comprehensive knowledge of various tools that fall in Spark Ecosystem like Spark SQL, Spark MlLib, Sqoop, Kafka, Flume and Spark Streaming\n    The capability to ingest data in HDFS using Sqoop & Flume, and analyze those large datasets stored in the HDFS\n    The power of handling real-time data feeds through a publish-subscribe messaging system like Kafka\n    The exposure to many real-life industry-based projects which will be executed using Edureka’s CloudLab\n    Projects which are diverse in nature covering banking, telecommunication, social media, and government domains\n    Rigorous involvement of an SME throughout the Spark Training to learn industry standards and best practices\n\n---------------------------------------------------\n\nWho should go for this course?\n\nThe market for Big Data Analytics is growing tremendously across the world and such a strong growth pattern followed by market demand is a great opportunity for all IT Professionals. Here are a few Professional IT groups, who are continuously enjoying the benefits and perks of moving into the Big Data domain.\n\n    Developers and Architects\n    BI /ETL/DW Professionals\n    Senior IT Professionals\n    Mainframe Professionals\n    Freshers\n    Big Data Architects, Engineers and Developers\n    Data Scientists and Analytics Professionals\n\n\n-------------------------------------------------------\n\nThere are no such prerequisites for Edureka’s PySpark Training Course. However, prior knowledge of Python Programming and SQL will be helpful but is not at all mandatory.\n\n--------------------------------------------------------\nPlease write back to us at sales@edureka.co or Call us at US: +18336900808 (Toll Free) or India: +918861301699\n\nFacebook: https://www.facebook.com/edurekaIN/\nTwitter: https://twitter.com/edurekain\nLinkedIn: https://www.linkedin.com/company/edureka"
