# Editing guidelines: https://github.com/watch-devtube/contrib/#how-to-edit-video-metadata

category: conference
tags:
    - ml
    - mobile
    - architecture
title: 'Visual Perception with Deep Learning'
language: English
recordingDate: 1207821470
description: "Google Tech Talks\nApril,  9 2008\n\nABSTRACT\n\nA long-term goal of Machine Learning research is to solve highy\ncomplex \"intelligent\" tasks, such as visual perception auditory\nperception, and language understanding. To reach that goal, the ML\ncommunity must solve two problems: the Deep Learning Problem, and the\nPartition Function Problem.\n\nThere is considerable theoretical and empirical evidence that complex\ntasks, such as invariant object recognition in vision, require \"deep\"\narchitectures, composed of multiple layers of trainable non-linear\nmodules. The Deep Learning Problem is related to the difficulty of\ntraining such deep architectures.\n\nSeveral methods have recently been proposed to train (or pre-train)\ndeep architectures in an unsupervised fashion. Each layer of the deep\narchitecture is composed of an encoder which computes a feature vector\nfrom the input, and a decoder which reconstructs the input from the\nfeatures. A large number of such layers can be stacked and trained\nsequentially, thereby learning a deep hierarchy of features with\nincreasing levels of abstraction. The training of each layer can be\nseen as shaping an energy landscape with low valleys around the\ntraining samples and high plateaus everywhere else. Forming these\nhigh plateaus constitute the so-called Partition Function problem.\n\nA particular class of methods for deep energy-based unsupervised\nlearning will be described that solves the Partition Function problem\nby imposing sparsity constraints on the features. The method can learn\nmultiple levels of sparse and overcomplete representations of\ndata. When applied to natural image patches, the method produces\nhierarchies of filters similar to those found in the mammalian visual\ncortex.\n\nAn application to category-level object recognition with invariance to\npose and illumination will be described (with a live demo). Another\napplication to vision-based navigation for off-road mobile robots will\nbe described (with videos). The system autonomously learns to\ndiscriminate obstacles from traversable areas at long range.\n\nThis is joint work with Y-Lan Boureau, Sumit Chopra, Raia Hadsell,\nFu-Jie Huang, Koray Kavakcuoglu, and Marc'Aurelio Ranzato.\n\nSpeaker: Yann Le Cun\nComputational and Biological Learning Lab, \nCourant Institute of Mathematical Sciences,\nNew York University."
