# Contribution guide: https://github.com/watch-devtube/contrib

# speaker:
#   name: _____
#   twitter: _____ # mandatory twitter handle; must not include @

# tags: [____, _____, _____]

title: 'Learn Live - Confusion matrix and data imbalances (Episode 8)'
language: English
recordingDate: 1635806257
description: "Learn Live: Foundations of Data Science for Machine Learning - Confusion matrix and data imbalances: November 1 – Episode 08\n\nJoin the chat and ask questions live at https://aka.ms/LearnLiveTV\n\nStarting Tuesday, September 14, 2021 (PST), join Jason DeBoever and Glenn Stephens live on Learn TV and explore this nine-part “Foundations of data science for machine learning” series. Each week, we will be walking through Learn modules and answering your questions live. From basic classical machine learning models to exploratory data analysis and customizing architectures, you’ll be guided by easy to digest conceptual content and interactive Jupyter notebooks and will learn about the underlying concepts as well as how to get into building models with the most common machine learning tools.\n\nNovember 1 - Episode 8:\nFollow along and complete the free, hands-on Microsoft Learn modules at https://aka.ms/LearnML-ConfusionMatrix\n\nHow do we know if a model is good or bad at classifying our data? The way that computers assess model performance sometimes can be difficult for us to comprehend or can over-simplify how the model will behave in the real world. To build models that work in a satisfactory way, we need to find intuitive ways to assess them, and understand how these metrics can bias our view. In this episode, you will:\n\nAssess performance of classification models.\nReview metrics to improve classification models.\nMitigate performance issues from data imbalances.\n\nMiss an episode? No problem, catch it on-demand: https://aka.ms/learnlive\n\n#AI #ML  #MachineLearning #Jupyter #LearnLive #Microsoft"
