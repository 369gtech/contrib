# Contribution guide: https://github.com/watch-devtube/contrib

# speaker:
#   name: _____
#   twitter: _____ # mandatory twitter handle; must not include @

# tags: [____, _____, _____]

title: 'Milvus 2.0: A Vector Database With Cloud-Native Architecture - Xiaomeng Yi, Zilliz'
language: English
recordingDate: 1639858941
description: "Don’t miss out! Join us at our next event: KubeCon + CloudNativeCon Europe 2022 in Valencia, Spain from May 17-20. Learn more at https://kubecon.io The conference features presentations from developers and end users of Kubernetes, Prometheus, Envoy, and all of the other CNCF-hosted projects.\n\nMilvus 2.0：一个云原生向量数据库 | Milvus 2.0: A Vector Database With Cloud-Native Architecture - Xiaomeng Yi, Zilliz\n\n矢量数据，即嵌入数据，是各种人工智能应用程序中常见的关键数据类型。矢量数据库出现的原因在于人工智能驱动的应用程序对非结构化数据分析的需求不断增长。Milvus 是一个开源的矢量数据库，也是一个 LF 人工智能和数据修匀项目，自其开源以来已获得了巨大的发展势头。在不到两年的时间里，Milvus 已在全世界获得了 1000 多个企业用户。在开发 Milvus 1.0 之后，我们总结了在服务于各种人工智能应用程序方面获得的经验教训。因此，我们设计了一个新的架构，并将其应用到 Milvus 2.0 中。该新架构实现了读写和计算存储的解耦，具有灵活、易于扩展和云原生的设计。在本演讲中，我们将展示指导开发 Milvus 2.0 的主要设计考虑因素。然后我们会介绍 Milvus 2.0 的系统架构和主要组成部分。最后，我们会讨论我们遇到的挑战。\n\nVector data, i.e., embedding data, is a common and critical data type in various AI applications. Vector databases were emerging due to the ever-growing demand for unstructured data analytics in AI-powered applications. Milvus, an open-source vector database and an LF AI & DATA graduation project, has gained huge momentum ever since its open-source. It has gained more than 1000 enterprise users worldwide in less than two years. After developing Milvus 1.0, we summarized the experiences and lessons learned from serving various AI applications. Accordingly, we designed a new architecture and applied it to Milvus 2.0. The new architecture achieves read-write and compute-storage decoupling with a flexible, easy-to-scale, and cloud-native design. In this talk, we will show the principal design considerations that guide the development of Milvus 2.0. Then we will introduce its system architecture and major components. Lastly, we will discuss the challenges we encountered."
