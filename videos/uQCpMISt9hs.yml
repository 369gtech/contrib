# Contribution guide: https://github.com/watch-devtube/contrib

# speaker:
#   name: _____
#   twitter: _____ # mandatory twitter handle; must not include @

# tags: [____, _____, _____]

title: 'State of Search 2021 (Transformers, Latest NLP Trends, Nearest Neighbor Search Models)'
language: English
recordingDate: 1630187802
description: "Utilizing machine learning models to improve search has been an immensely active area for several years now. Some promises were kept, many others were broken. With the rise of Transformer models like BERT we seem to finally be entering a chapter, where models not only perform well in the research lab but actually make their way into the production stack. \n\nNow that almost every English Google search query is powered by a Transformer [1], it is clear that these models improve the search experience, and can do so at scale. As Transformers only rely on text, the transition from web search to a custom enterprise search seems more tempting than ever.\n\nIn this talk, we will dive into some of the most promising methods and show how to ... \n\n… improve document retrieval via dense passage retrieval \n… return more granular search results by showing direct answers to user’s questions\n… scale those pipelines via DAGs and Approx. Nearest Neighbour search (ANN) for production workloads\n… avoid common pitfalls when moving to production\n\nAll methods will be illustrated with code examples based on the open-source framework Haystack [2] so that participants can easily reproduce them at home and let the transformers into their production stack - one by one and carefully selected!\n\nPUBLICATION PERMISSIONS:\nOriginal video was published with the Creative Commons Attribution license (reuse allowed). Link: https://www.youtube.com/watch?v=0FHdB00Mx7c"
