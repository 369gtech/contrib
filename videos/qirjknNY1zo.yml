# Editing guidelines: https://github.com/watch-devtube/contrib/#how-to-edit-video-metadata

category: conference
speaker:
    name: 'Siraj Raval'
    twitter: sirajraval
    matches: [sirajraval]
title: 'Synthetic Gradients Explained'
language: English
recordingDate: 1508870126
description: "DeepMind released an optimization strategy that could become the most popular approach for training very deep neural networks, even more so than backpropagation. I don't think it got enough love, so i'm going to explain how it works myself and why i think it's so cool. Already know how backpropagation works? Skip to 14:10 \n\nCode for this video:\nhttps://github.com/llSourcell/synthetic_gradients_explained\n\nPlease Subscribe! And like. And comment. Thats what keeps me going. \n\nFollow me on:\nTwitter: https://twitter.com/sirajraval\n\nFacebook: https://www.facebook.com/sirajology/\nSnapchat: @llSourcell\n\nMore learning resources: \nhttps://iamtrask.github.io/2017/03/21/synthetic-gradients/\nhttps://arxiv.org/abs/1703.00522\nhttps://deepmind.com/blog/decoupled-neural-networks-using-synthetic-gradients/\n\nJoin us in the Wizards Slack channel:\nhttp://wizards.herokuapp.com/\n\nAnd please support me on Patreon: https://www.patreon.com/user?u=3191693 Instagram: https://www.instagram.com/sirajraval/"
