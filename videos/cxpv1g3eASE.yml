# Editing guidelines: https://github.com/watch-devtube/contrib/#how-to-edit-video-metadata


tags:
    - unix
    - testing
title: 'Intel GFX CI: Validation done the Linux way'
language: English
recordingDate: 1549739222
description: "by Martin Peres\n\nAt: FOSDEM 2019\nhttps://video.fosdem.org/2019/K.4.401/igt_ci.webm\n\n\nThe Linux community is slowly moving towards better quality trough automated testing to prevent regressions in mainline and stable trees. However, Linux is full of HW-specific code which makes validation of patches impossible for individual developers, which leads to regressions. In this talk, we will explain how we solved these issues by getting inspired by Linux's development model, and how we extend it to the development of our testsuite, CI infrastructure and bug handling. \n\nAfter 2 years of activity, this led Linus Torvalds to say i915's quality has greatly improved compared to other graphic drivers. Linux's development model has been described as being\nakin to a bazaar, where any developer can make changes to Linux as long\nas they strictly improve the state of Linux, without regressing any\napplication that currently runs on it. This allows Linux users to update\ntheir kernels and benefit from the work of all developers, without\nhaving to fix anything in their applications when a new version comes.\nUnfortunately, it is impossible for developers to try their changes on\nall the different hardware and userspace combination being used in the wild. \n\nTypically, a developer will mostly test the feature he/she is working on\nwith the hardware at hand before submitting the patch for review. Once\nreviewed, the patch can land in a staging repository controlled by the\nmaintainer of the subsystem the patch is changing. Validation of the\nstaging tree is then performed ahead of sending these changes to Linus\nTorvalds (or one of his maintainers). Regressions caught at this point\nrequire to bisect the issue, which is time consuming and usually done by\na separate team, which may become a bottleneck. Sometimes they let\nregressions through, hoping to be able to fix them during the -rc cycles. \n\nTo address this bottleneck, the developer should be responsible for\nvalidating the change completely. This leads to a virtuous cycle as not\nonly developers can rework their patches until they do not break\nanything (saving the time of other people), but they also become more\naware of the interaction their changes have on userspace, which improves\ntheir understanding of the driver which leads to better future patches. \n\nTo enable putting the full cost of integration on developers, validation\nneeds to become 100% automated, have 100% code/HW coverage of the\nuserspace usecases, and provide timely validation results to even the\nmost time-pressured developers. To reach these really ambitious\nobjectives, driver developers and validation engineers need to be\nconsidered as one team. The CI system developers need to provide a\nsystem capable of reaching the objectives, and driver developers need to\ndevelop a test suite capable of reaching the goal of having 100% code\ncoverage of the whole driver on the CI system provided to them. \n\nFinally, this increase in understanding of how validation is done allows\ndevelopers to know if their patch series will be properly validated,\nwhich reduces the risk of letting regressions land in Linux. \n\nThe devil however lies in the details, so in this talk, we will explain\nhow we are going from theory to practice, what is our current status and\nwhat we are doing to get closer to our ambitious goal! We will describe\nthe current developer workflow and demonstrate how we empowered\ndevelopers by providing timely testing as a transparent service to\nanyone sending patches to our mailing lists. \n\nRoom: K.4.401\nScheduled start: 2019-02-02 11:00:00+01"
