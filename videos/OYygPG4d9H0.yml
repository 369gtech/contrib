# Editing guidelines: https://github.com/watch-devtube/contrib/#how-to-edit-video-metadata

tags:
    - architecture
    - python
title: 'Understanding and Applying Self-Attention for NLP - Ivan Bilan'
language: English
recordingDate: 1533145412
description: "PyData Berlin 2018\n\nUnderstanding attention mechanisms and self-attention, presented in Google's \"Attention is all you need\" paper, is a beneficial skill for anyone who works on complex NLP problems. In this talk, we will go over the main parts of the Google Transformer self-attention model and the intuition behind it. Then we will look on how this architecture can be used for other NLP tasks, i.e. slot filling.\n\nSlides: https://www.dropbox.com/s/hri8veio4rep5g4/Self-Attention_for_NLP_by_Ivan_Bilan.pptx?dl=0\n---\nwww.pydata.org\n\nPyData is an educational program of NumFOCUS, a 501(c)3 non-profit organization in the United States. PyData provides a forum for the international community of users and developers of data analysis tools to share ideas and learn from each other. The global PyData network promotes discussion of best practices, new approaches, and emerging technologies for data management, processing, analytics, and visualization. PyData communities approach data science using many languages, including (but not limited to) Python, Julia, and R. \n\nPyData conferences aim to be accessible and community-driven, with novice to advanced level presentations. PyData tutorials and talks bring attendees the latest project features along with cutting-edge use cases."
