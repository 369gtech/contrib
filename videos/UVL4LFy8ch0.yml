# Editing guidelines: https://github.com/watch-devtube/contrib/#how-to-edit-video-metadata

tags:
    - bigdata
    - performance
    - python
title: 'Pierre Glaser - Parallel computing in Python: Current state and recent advances'
language: English
recordingDate: 1569920551
description: "\"Parallel computing in Python: Current state and recent advances\n[EuroPython 2019 - Talk - 2019-07-12 - Osaka / Samarkand]\n[Basel, CH]\n\nBy Pierre Glaser\n\nh2Parallel computing in Python: Current state and recent advances/h2\n\nModern hardware is multi-core. It is crucial for Python to provide\nhigh-performance parallelism. This talk will expose to both data-scientists and\nlibrary developers the current state of affairs and the recent advances for\nparallel computing with Python. The goal is to help practitioners and\ndevelopers to make better decisions on this matter.\n\nI will first cover how Python can interface with parallelism, from leveraging\nexternal parallelism of C-extensions –especially the BLAS family– to Python's\nmultiprocessing and multithreading API. I will touch upon use cases, e.g single\nvs multi machine, as well as and pros and cons of the various solutions for\neach use case. Most of these considerations will be backed by benchmarks from\nthe scikit-learn machine\nlearning library.\n\nFrom these low-level interfaces emerged higher-level parallel processing\nlibraries, such as concurrent.futures, joblib and loky (used by dask and\nscikit-learn) These libraries make it easy for Python programmers to use safe\nand reliable parallelism in their code. They can even work in more exotic\nsituations, such as interactive sessions, in which Python’s native\nmultiprocessing support tends to fail. I will describe their purpose as well as\nthe canonical use-cases they address.\n\nThe last part of this talk will focus on the most recent advances in the Python\nstandard library, addressing one of the principal performance bottlenecks of\nmulti-core/multi-machine processing, which is data communication. We will\npresent a new API for shared-memory management between different Python\nprocesses, and performance improvements for the serialization of large Python\nobjects ( PEP 574, pickle extensions). These performance improvements will be\nleveraged by distributed data science frameworks such as dask, ray and pyspark.\n\n\n\nLicense: This video is licensed under the CC BY-NC-SA 3.0 license: https://creativecommons.org/licenses/by-nc-sa/3.0/\nPlease see our speaker release agreement for details: https://ep2019.europython.eu/events/speaker-release-agreement/"
