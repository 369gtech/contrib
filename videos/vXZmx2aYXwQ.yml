# Contribution guide: https://github.com/watch-devtube/contrib

# speaker:
#   name: _____
#   twitter: _____ # mandatory twitter handle; must not include @

# tags: [____, _____, _____]

title: 'Transparent Open Source AI Video Analytics with Panfrost'
language: English
recordingDate: 1612054240
description: "Aaron Boxer, Marcus Edel\n\nhttps://lca2021.linux.org.au/schedule/presentation/53/\n\nAI-powered video analytics is one of the most challenging applications of\r\nAI to edge devices, given the edge's power, compute, and memory limitations.\r\nThis area is currently dominated by NVidia Deep Stream, which suffers from:\r\n\r\n1. vendor-lock-in from CUDA language and NVidia hardware\r\n\r\n2. lack of transparency into low level tensor operations and algorithms due to\r\nclosed source drivers and libraries.\r\n\r\nCan we give freedom of choice back to AI multimedia developers ?\r\n\r\nCan we build a pure open source stack, running from application to ML framework\r\ndown to GPU driver, which allows complete transparency into the ML inference\r\nworkflow ?\r\n\r\nThe new Panfrost open source driver for Mali GPUs is solving this problem\r\non the edge by enabling a fast and efficient machine learning stack\r\nrunning pure open source. Combining this with TensorFlow Lite and GStreamer,\r\nwe get a powerful open source AI stack for video analytics. And because\r\nthe stack is open from top to bottom, we get visibility into the complete\r\ninference process, allowing us to better understand and explain how an \r\nanalytic model makes its predictions.\r\n\r\nThe ability to explain how a model infers it's results (explainability) is an\r\nincreasingly desirable ML feature, particularly in applications that have an impact\r\non privacy, such as video facial recognition. Explainability allows us to build\r\nethical and trustworthy ML systems known to be free from bias. \r\nClosed source blobs and libraries interfere with explainability by hiding\r\ncrucial computations from view. \r\n\r\nIn this talk, we will walk through the process of building an AI-driven multimedia\r\npipeline on top of a completely open source inference stack:\r\nopen source GPU driver, machine learning framework and machine learning models.\r\nWe will share what we have learned about optimizing these models to run fast\r\non resource-constrained hardware such as the Rockchip RK3399. And we will discuss\r\nhow this completely open stack is a critical component of ethical and trustworthy\r\nvideo analytics.\n\nlinux.conf.au is a conference about the Linux operating system, and all aspects of the thriving ecosystem of Free and Open Source Software that has grown up around it. Run since 1999, in a different Australian or New Zealand city each year, by a team of local volunteers, LCA invites more than 500 people to learn from the people who shape the future of Open Source. For more information on the conference see https://linux.conf.au/\n\nProduced by Next Day Video Australia: https://nextdayvideo.com.au\n\n#linux.conf.au #linux #foss #opensource\n\nSun Jan 24 14:25:00 2021 at Pia Andrews Conservatory"
